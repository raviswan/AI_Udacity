AI NOTES

Minimax search and Alpha-Beta Pruning: https://www.cs.cornell.edu/courses/cs312/2002sp/lectures/rec21.htm

DFS, BFS: https://mhesham.wordpress.com/tag/iterative-deepening-depth-first-search/

------- Submitting project -------

source activate aind
source deactivate aind
udacity submit <projname>


- AI terms: Roomba example. Agent, State, Action, Cognition.

-------------------------------------------------------------------------
		Min-Max / ISOLATION-GAME 
-------------------------------------------------------------------------

- Remember the game where we , player has to be the last to make a move. It's also called Isolation game.

- Your goal is to maximize number of moves. Your opponents goal is to minimize number of moves. For this we gotta , do bottoms-up. Look at the terminating condition. If you win, count it as +1, if opponent wins, make it -1. These values can be anything but the bigger the range between them, better the outcome.

- At your level, your job is to maximize the outcome. Therefore, from your child branches, you pick the max. value of all child branches (for our example +1). At min. level, your opponent would do the opposite. That is pick a minimum value of -1. This percolates all the way to the top to let you visualize which is the best move that yields +1. 

- As the board size gets bigger, the number of combinations to consider at the each level gets exponentially bigger. So we gotta come up with better ways to play in the limited time we get. One way is to limit the number of branches you consider at each level. For e.g at the start of 5x5 game, the "DEPTH", d= 25.

- If you start, you have 25 places to choose from, and your opponent has 24 places to choose from. After that , you don't really have 23 sub-branches to consider for your next move. Some of them may be blocked off. When you run average, you determine that only 9 branches on an average are required per move. Think logically, by the time you get towards the end of the game, you'd have 4 moves to make, you oppoent would have 3, you 2, your opponent 1 and then you lose.
Now, if we assume we can look athe only 8 branches (called "BRANCHING FACTOR" b) at each level, which branch would you pick. You need a metric for that.   It is established that number of "nodes" minimax" will need to visit is (b^d). In this example, that would be 8^25. This is where you need a heuristic function to compute the metrics . A simple one would be #my_moves. So at the every level, you compute number of remaining moves for you.

If you have a multiplayer isolation game, you form a set of of (3 metrics for 3 player game at each level). [a,b,c]. At the Level 3, you pick the set that maximizes `c` , and propogate it upward. At level 2,
you pick the set that maximizes 'b'. And at level 1, you pick the set that maximizes 'a'.

Now if you have probability of how often a position is likely to be picked , then it's best to have a range for maximum value each player metric can take . For e.g, if the range is [-10:10], and lets say at a given level, the probability of picking a move is 0.9, and the max metric at the level below that is 10. Then, at current level, you'd have 0.9*10 = 9 . You can denote this as >=9. Now compare this with the peers and you can do what is called Alpha-beta pruning. 



--------DEPTH LIMITED SEARCH ------
In this, you basically go upto a fixed depth and return the metrics from there instead of waiting to hit terminal condition. 
Quiescence is when your branch that is pickec starts to remain the same as you go deeper and deeper.

-------ITERATIVE FIRST DEEPENING SEARCH-----

http://www.geeksforgeeks.org/iterative-deepening-searchids-iterative-deepening-depth-first-searchiddfs/

In iterative deepening, for every move, you run alphabeta function for all depths starting from 0 until until you run out of time. 

----- ALPHA BETA Pruning -----
Essentially at every minmax level, you compute the local min or local max, starting from left-most branch. And use that
to prune other moves for the same "for" loop.  

For instance, in max(),  you adjust the alpha for max computation to essentially find values >= alpha for subsequent "for" loop entries of the max(). And this alpha is passed down to the min() one level down  as part of the next index of  "for" loop of the current max (). And if that entry in min() returns a value that is less than alpha we passed in, don't do further computation in min(). Just return. So you pruned the tree.

In min(),  you adjust the beta for min computation to essentially find values <= beta for subsequent "for" loop entries of the min (). And this beta is passed down to the max() one level down as part of the next index of "for" loop of the current min(). And if that entry in the max() returns a value that is greater than beta we passed in, don't do further computation in max(). Just return. So you pruned the tree.


-------------------------------------------------------------------------
		SEARCH ALGORITHMS 
-------------------------------------------------------------------------
Remember: Frontier set, Explored set and UnExplored set.

BFS: Shortest paths are added first. The new paths are added to the end of the path list. Might need to store 2^n.

Cheapest Cost First: always picks the cheapest path. After new paths are added, it still picks the shortest. So it goes back and forth. Optimal as well.

DFS: Can go on and on. Not optimal. But advantage is very few past states required to store. Of order of n.

A* search: its combo of bfs with heuristic.

goal is to minimize function 
f = g + h
where g - path cost as before
	  h - heuristic to estimate cost to reach goal from that state with cost g. For destination, it can be st. line distance from 
	  		intermediate point to the goal.

You always pick the minimum f as you continue exploring.







